{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from system.flcore.trainmodel.resnet import *\n",
    "import torch\n",
    "model_1 = resnet18_low(num_classes=10, has_bn=True, bn_block_num=4).to(\"cuda:0\")\n",
    "# model.fc = torch.nn.Identity()\n",
    "print(model_1)\n",
    "from socketserver import ThreadingUDPServer\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "raw_data = 'data/Cifar10/'\n",
    "transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "        root=raw_data+\"rawdata\", train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "root=raw_data+\"rawdata\", train=False, download=True, transform=transform)\n",
    "    \n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=64, shuffle=True, drop_last=True)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=64, shuffle=True, drop_last=True)\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "model_1.train()\n",
    "criterion = nn.CrossEntropyLoss()  # 假设我们的任务是分类\n",
    "optimizer = SGD(model_1.parameters(), lr=0.001, momentum=0.9)  # 使用SGD优化器\n",
    "\n",
    "# 定义学习率调度器\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.99)\n",
    "# 训练模型\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model_1.train()  # 设置模型为训练模式\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(\"cuda:0\")\n",
    "        labels = labels.to(\"cuda:0\")\n",
    "        optimizer.zero_grad()  # 清空之前的梯度\n",
    "        _, _, x = model_1(inputs)  # 获得模型的输出\n",
    "        loss = criterion(x, torch.tensor(labels))  # 计算损失\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新参数\n",
    "\n",
    "        running_loss += loss.item()  # 累加损失\n",
    "\n",
    "        # 每batch打印一次损失\n",
    "        if i % 100 == 99:  # 每100个batch打印一次\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            print('[Epoch: %d, Batch: %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "            _, predicted = torch.max(x.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            print('Train Accuracy: %d %%' % (100 * correct / total))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # 更新学习率\n",
    "    scheduler.step()\n",
    "\n",
    "    # 在每个epoch结束时，验证模型性能\n",
    "    model_1.eval()  # 设置模型为评估模式\n",
    "    with torch.no_grad():  # 禁用梯度计算\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images = images.to(\"cuda\")\n",
    "            _, _, x = model_1(images)\n",
    "            _, predicted = torch.max(x.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted.cpu() == labels).sum().item()\n",
    "\n",
    "        print('Epoch %d Test Accuracy: %d %%' % (epoch + 1, 100 * correct / total))\n",
    "def agg_func(protos):\n",
    "    for [label, proto_list] in protos.items():\n",
    "        if len(proto_list) > 1:\n",
    "            proto = 0 * proto_list[0].data\n",
    "            for i in proto_list:\n",
    "                proto += i.data\n",
    "            protos[label] = proto / len(proto_list)\n",
    "        else:\n",
    "            protos[label] = proto_list[0] #只有一个，不需要平均了\n",
    "\n",
    "    return protos #不一定包含所有种类\n",
    "\n",
    "def save_embedding(protos, is_high=True):\n",
    "    protos = torch.tensor(protos)\n",
    "    if is_high: protos.save(\"high.pt\")\n",
    "    else: protos.save(\"low.pt\")\n",
    "model_1.eval()\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import copy\n",
    "\n",
    "protos = defaultdict(list)\n",
    "device = \"cuda:0\"\n",
    "low_protos = defaultdict(list)\n",
    "with torch.no_grad():\n",
    "    for i, (x, y) in enumerate(trainloader):\n",
    "        if type(x) == type([]):\n",
    "            x[0] = x[0].to(device)\n",
    "        else:\n",
    "            x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        low, rep, _ = model_1(x)\n",
    "        rep = F.normalize(rep, dim=1) #[batch, dim(512，对于resnet18)]\n",
    "        low = F.normalize(low, dim=1)\n",
    "        for i, yy in enumerate(y):\n",
    "            y_c = yy.item()\n",
    "            protos[y_c].append(rep[i, :].detach().data)\n",
    "            low_protos[y_c].append(low[i, :].detach().data)\n",
    "        \n",
    "agg_protos = agg_func(copy.deepcopy(protos))\n",
    "agg_low_protos = agg_func(copy.deepcopy(low_protos))\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# 假设 protos 是一个字典，键（label）是类别，值（embeddings）是嵌入向量的列表\n",
    "# 首先，我们需要提取所有的嵌入向量并将它们合并成一个大的列表\n",
    "all_embeddings = [emb for embeddings in protos.values() for emb in embeddings]\n",
    "\n",
    "# 将 PyTorch 张量转换为 NumPy 数组\n",
    "all_embeddings_np = np.array([emb.cpu().numpy() for emb in all_embeddings])\n",
    "\n",
    "# 应用 t-SNE 算法\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=0, learning_rate=200)\n",
    "high_embeddings = tsne.fit_transform(all_embeddings_np)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# 提取每个嵌入向量对应的类别标签\n",
    "labels = [k for k, v in protos.items() for _ in v]\n",
    "\n",
    "# 为了图例，我们存储每个类别的属性\n",
    "legend_entries = []\n",
    "markers = ['o','v','.','3','*','+','x','h','s','D']\n",
    "\n",
    "# 创建三维散点图\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# 绘制每个类别的点\n",
    "for label in set(labels):\n",
    "    indices_to_keep = [i for i, x in enumerate(labels) if x == label]\n",
    "    # 为每个类别选择不同的颜色和点的形状\n",
    "    color = f'C{label % 10}'  # 使用 'C0' 到 'C9' 表示颜色\n",
    "    marker = markers[label]  # 选择一个标记样式\n",
    "    ax.scatter(high_embeddings[indices_to_keep, 0], high_embeddings[indices_to_keep, 1], label, color=color, marker=marker, label=label)\n",
    "    # 为图例添加条目\n",
    "    legend_entries.append(plt.Line2D([0], [0], color=color, marker=marker, linestyle='None', markersize=6, label=label))\n",
    "    ax.scatter(high_embeddings[indices_to_keep, 0], high_embeddings[indices_to_keep, 1], label, s=2)\n",
    "\n",
    "\n",
    "# 设置图表标题和坐标轴标签\n",
    "ax.set_title('t-SNE visualization of embeddings by category (3D)')\n",
    "ax.set_xlabel('Dimension 1')\n",
    "ax.set_ylabel('Dimension 2')\n",
    "ax.set_zlabel('Category Layer')\n",
    "\n",
    "# 显示图例\n",
    "ax.legend(handles=legend_entries, loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
